{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "#import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "#### very simple: keep lower case text only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/train.csv' does not exist: b'data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fc81c95b28cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrawData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrawData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wordList'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_to_word_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/sandbox/tf/tf2/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/sandbox/tf/tf2/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/sandbox/tf/tf2/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/sandbox/tf/tf2/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/sandbox/tf/tf2/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/train.csv' does not exist: b'data/train.csv'"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"data/train.csv\")\n",
    "rawData['wordList'] = rawData['text'].apply(text_to_word_sequence)\n",
    "target = rawData.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>wordList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[all, residents, asked, to, 'shelter, in, plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[13, 000, people, receive, wildfires, evacuati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[two, giant, cranes, holding, a, bridge, colla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[aria, ahrary, thetawniest, the, out, of, cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>[m1, 94, 01, 04, utc, 5km, s, of, volcano, haw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[police, investigating, after, an, e, bike, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, latest, more, homes, razed, by, northern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                               wordList  \n",
       "0     [our, deeds, are, the, reason, of, this, earth...  \n",
       "1         [forest, fire, near, la, ronge, sask, canada]  \n",
       "2     [all, residents, asked, to, 'shelter, in, plac...  \n",
       "3     [13, 000, people, receive, wildfires, evacuati...  \n",
       "4     [just, got, sent, this, photo, from, ruby, ala...  \n",
       "...                                                 ...  \n",
       "7608  [two, giant, cranes, holding, a, bridge, colla...  \n",
       "7609  [aria, ahrary, thetawniest, the, out, of, cont...  \n",
       "7610  [m1, 94, 01, 04, utc, 5km, s, of, volcano, haw...  \n",
       "7611  [police, investigating, after, an, e, bike, co...  \n",
       "7612  [the, latest, more, homes, razed, by, northern...  \n",
       "\n",
       "[7613 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'tweet lenght distribution')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rawData['wordList'].apply(lambda x: len(x)).hist()\n",
    "plt.title('tweet lenght distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## proto 0: use Gloves as frozen embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"data/glove.twitter.27B.25d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for end-to-end optimization, add a embedding layer, preinitialized with Glove\n",
    "```python \n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")\n",
    "```\n",
    "where *embedding_matrix* is found from glove data, see https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_embed(word,gloveSize=25):\n",
    "    try: \n",
    "        vector = embeddings_dict[word]\n",
    "    except: \n",
    "        vector = np.zeros(25)\n",
    "    return vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData['vectorList'] = rawData['wordList'].apply(lambda wordList: [try_embed(word) for word in wordList]).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.2047e-01,  5.6526e-01, -3.3577e-02,  3.1019e-01,  1.8930e-01,\n",
       "        -6.4588e-01,  1.3876e+00, -5.7484e-01, -1.3896e-01, -3.9003e-01,\n",
       "        -1.6911e-01, -7.3094e-02, -5.7021e+00,  8.1264e-01, -4.1284e-01,\n",
       "        -4.3867e-01,  3.6185e-01, -3.4471e-01,  1.4653e-01,  7.6999e-02,\n",
       "        -1.2756e+00, -6.3190e-01, -6.3516e-01, -5.1729e-01, -9.0167e-01],\n",
       "       [-4.8785e-01, -6.1645e-02, -4.7218e-01,  1.6183e+00, -6.6795e-01,\n",
       "        -3.0409e-01,  7.5985e-01, -1.6000e+00,  5.5671e-02, -6.8337e-01,\n",
       "        -6.9001e-02,  7.3243e-01, -2.1834e+00,  1.3285e+00, -7.9413e-01,\n",
       "        -5.0598e-01,  1.7160e-01,  6.4233e-01,  1.2438e+00, -2.0530e-01,\n",
       "         8.6138e-02,  1.0546e+00, -1.2763e+00,  2.8084e-02, -1.6438e-01],\n",
       "       [ 1.8660e-01, -9.8326e-02, -1.2268e-01, -9.3822e-01, -4.0161e-01,\n",
       "         6.3830e-01,  1.6686e+00, -6.8036e-01, -9.8359e-01, -7.9512e-02,\n",
       "         3.8078e-01,  3.9076e-02, -5.4147e+00,  2.8290e-02, -4.7007e-01,\n",
       "         1.1377e-01, -5.2725e-01, -7.9312e-01,  5.8203e-01, -6.1829e-01,\n",
       "         3.7025e-01,  2.2610e-01, -7.3014e-01, -1.0190e-01, -2.1382e-01],\n",
       "       [-1.0167e-02,  2.0194e-02,  2.1473e-01,  1.7289e-01, -4.3659e-01,\n",
       "        -1.4687e-01,  1.8429e+00, -1.5753e-01,  1.8187e-01, -3.1782e-01,\n",
       "         6.8390e-02,  5.1776e-01, -6.3371e+00,  4.8066e-01,  1.3777e-01,\n",
       "        -4.8568e-01,  3.9000e-01, -1.9506e-03, -1.0218e-01,  2.1262e-01,\n",
       "        -8.6146e-01,  1.7263e-01,  1.8783e-01, -8.4250e-01, -3.1208e-01],\n",
       "       [ 4.3525e-01,  4.1565e-01, -4.9016e-03,  3.3494e-01, -9.3569e-02,\n",
       "         2.3100e-02,  1.8699e+00, -5.7324e-01, -6.1937e-01,  1.1542e-01,\n",
       "        -9.0317e-01,  5.9846e-01, -4.3689e+00,  1.5006e-01,  3.7120e-02,\n",
       "         5.2517e-01,  5.2408e-02, -2.2282e-01,  5.7383e-01, -5.5142e-01,\n",
       "         6.5294e-01,  4.3788e-01,  3.7033e-01,  1.2756e-01, -7.3918e-01],\n",
       "       [ 3.2543e-01, -8.9637e-02, -1.4733e-01,  4.2850e-01, -9.2613e-02,\n",
       "        -1.7938e-01,  1.2835e+00, -5.9714e-01, -2.8134e-01, -4.8954e-02,\n",
       "         5.4827e-01,  6.9410e-01, -6.1200e+00,  6.7240e-01,  1.8078e-02,\n",
       "        -2.4165e-01,  5.0342e-01,  6.5325e-01, -2.0674e-01,  2.7639e-01,\n",
       "        -7.9097e-01,  1.0432e-01, -6.1750e-01, -5.4592e-01, -6.9893e-02],\n",
       "       [-1.7895e-01,  3.8406e-01,  7.3035e-02, -3.2363e-01, -9.2441e-02,\n",
       "        -4.0767e-01,  2.1000e+00, -1.1363e-01, -5.8784e-01, -1.7034e-01,\n",
       "        -6.4330e-01,  7.2388e-01, -5.7839e+00, -1.0406e-01,  5.2152e-01,\n",
       "        -1.1314e-01,  5.9554e-01, -4.7587e-01, -4.5510e-01,  8.4431e-02,\n",
       "        -4.5820e-01, -1.6727e-01,  5.4594e-01,  3.5478e-02, -1.6073e-01],\n",
       "       [-7.2555e-02,  1.8086e-01,  8.6127e-02, -5.9598e-01, -1.0356e+00,\n",
       "        -2.5421e-01,  1.6443e+00, -3.9587e-01,  7.3338e-01,  7.6447e-01,\n",
       "         2.6876e-01,  6.3445e-01, -1.6045e+00,  1.7964e+00,  1.2823e+00,\n",
       "        -3.8578e-01,  5.6998e-01,  1.4136e+00,  1.2666e+00, -1.4590e-01,\n",
       "        -1.2274e-01, -3.6123e-01,  1.4509e+00, -8.9175e-01,  5.4023e-01],\n",
       "       [ 5.8920e-02, -8.0419e-01, -1.2289e-01, -6.7338e-01, -6.0535e-01,\n",
       "        -1.0329e+00,  1.9280e+00,  2.1638e-01,  6.7993e-01,  2.5998e-01,\n",
       "        -2.4427e-01, -4.9064e-01, -4.0699e+00,  1.8488e+00,  4.6267e-02,\n",
       "         7.1674e-02,  1.2726e+00, -4.9288e-02,  4.8783e-01, -1.5917e+00,\n",
       "        -3.6507e-01,  3.7430e-01, -4.4852e-01,  1.1021e+00, -8.1738e-01],\n",
       "       [-3.1158e-01, -1.4212e-01, -6.6915e-01,  8.4029e-01, -1.5580e+00,\n",
       "         5.6011e-01, -6.1683e-01,  1.6980e+00, -4.1210e-01,  2.4126e+00,\n",
       "        -3.8526e-01,  4.5102e-01, -2.5557e+00,  2.1710e+00, -1.0902e+00,\n",
       "        -7.4343e-01, -1.9013e-01, -1.6993e-01, -8.0078e-01, -8.9488e-01,\n",
       "         8.1421e-01,  5.6424e-02, -2.0917e+00,  8.3719e-01, -1.8743e+00],\n",
       "       [-2.5195e-01,  5.2472e-01, -1.3177e+00,  1.7307e+00, -1.3704e+00,\n",
       "        -3.9519e-01,  1.2037e+00, -5.1404e-01, -8.0616e-01,  1.7397e-03,\n",
       "        -1.1042e+00,  7.7293e-01, -3.5411e+00,  4.4504e-01, -5.1759e-01,\n",
       "         4.9451e-01, -2.4948e-01, -1.2327e-01,  1.2067e+00, -1.4879e+00,\n",
       "         1.1286e+00,  9.5427e-01, -7.8054e-01,  8.6340e-01, -6.2875e-01],\n",
       "       [ 3.8727e-01,  6.7913e-01, -5.1213e-01,  1.7087e-01, -6.4201e-01,\n",
       "        -7.4063e-01,  7.5364e-01, -2.4487e-01, -2.3779e-01,  1.8933e-01,\n",
       "        -2.0555e-01, -7.2817e-02, -5.4575e+00,  6.7533e-01, -3.7257e-01,\n",
       "        -2.6562e-01, -1.5686e-02, -6.4157e-01,  5.5260e-02, -5.1445e-01,\n",
       "        -3.4685e-01, -3.7239e-01, -2.8049e-01, -3.6892e-01, -5.5413e-01],\n",
       "       [-1.8232e-01,  9.6997e-01,  3.2174e-01, -7.4793e-02, -1.1618e-01,\n",
       "         9.5187e-02,  1.4986e+00, -4.1357e-01, -8.6298e-01,  4.2067e-01,\n",
       "        -5.3125e-01,  1.0797e-01, -5.5600e+00,  2.5913e-01, -5.8389e-01,\n",
       "         1.2241e-01, -1.5168e-01, -7.1983e-01, -1.6605e-01, -9.2514e-02,\n",
       "        -3.4099e-01,  1.2464e-01,  8.6193e-02, -1.4110e-01, -1.8656e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData['vectorList'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloveSize = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullDimMatrix(matrix):\n",
    "    fullDim = np.zeros((maxTextLength,gloveSize))\n",
    "    fullDim[0:matrix.shape[0],:] += matrix\n",
    "    return fullDim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData['fullSizeVectorMatrix'] = rawData['vectorList'].apply(lambda matrix :np.asarray(fullDimMatrix(matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>wordList</th>\n",
       "      <th>vectorList</th>\n",
       "      <th>fullSizeVectorMatrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "      <td>[[-0.42047, 0.56526, -0.033577, 0.31019, 0.189...</td>\n",
       "      <td>[[-0.4204699993133545, 0.5652599930763245, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>[[-1.2358, -0.58127, 0.20145, 0.01657, -1.3504...</td>\n",
       "      <td>[[-1.23580002784729, -0.5812699794769287, 0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[all, residents, asked, to, 'shelter, in, plac...</td>\n",
       "      <td>[[-0.1823199987411499, 0.9699699878692627, 0.3...</td>\n",
       "      <td>[[-0.1823199987411499, 0.9699699878692627, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[13, 000, people, receive, wildfires, evacuati...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "      <td>[[-0.35518, 0.4803, 0.49681, -0.76379, -0.6458...</td>\n",
       "      <td>[[-0.3551799952983856, 0.48030000925064087, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[two, giant, cranes, holding, a, bridge, colla...</td>\n",
       "      <td>[[0.5829600095748901, 0.44516998529434204, 1.0...</td>\n",
       "      <td>[[0.5829600095748901, 0.44516998529434204, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[aria, ahrary, thetawniest, the, out, of, cont...</td>\n",
       "      <td>[[-1.1461000442504883, -0.18153999745845795, 0...</td>\n",
       "      <td>[[-1.1461000442504883, -0.18153999745845795, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>[m1, 94, 01, 04, utc, 5km, s, of, volcano, haw...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[police, investigating, after, an, e, bike, co...</td>\n",
       "      <td>[[0.30003, 0.34859, -0.2896, -0.30224, -0.5052...</td>\n",
       "      <td>[[0.300029993057251, 0.3485899865627289, -0.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, latest, more, homes, razed, by, northern...</td>\n",
       "      <td>[[-0.010166999883949757, 0.020193999633193016,...</td>\n",
       "      <td>[[-0.010166999883949757, 0.020193999633193016,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                               wordList  \\\n",
       "0     [our, deeds, are, the, reason, of, this, earth...   \n",
       "1         [forest, fire, near, la, ronge, sask, canada]   \n",
       "2     [all, residents, asked, to, 'shelter, in, plac...   \n",
       "3     [13, 000, people, receive, wildfires, evacuati...   \n",
       "4     [just, got, sent, this, photo, from, ruby, ala...   \n",
       "...                                                 ...   \n",
       "7608  [two, giant, cranes, holding, a, bridge, colla...   \n",
       "7609  [aria, ahrary, thetawniest, the, out, of, cont...   \n",
       "7610  [m1, 94, 01, 04, utc, 5km, s, of, volcano, haw...   \n",
       "7611  [police, investigating, after, an, e, bike, co...   \n",
       "7612  [the, latest, more, homes, razed, by, northern...   \n",
       "\n",
       "                                             vectorList  \\\n",
       "0     [[-0.42047, 0.56526, -0.033577, 0.31019, 0.189...   \n",
       "1     [[-1.2358, -0.58127, 0.20145, 0.01657, -1.3504...   \n",
       "2     [[-0.1823199987411499, 0.9699699878692627, 0.3...   \n",
       "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4     [[-0.35518, 0.4803, 0.49681, -0.76379, -0.6458...   \n",
       "...                                                 ...   \n",
       "7608  [[0.5829600095748901, 0.44516998529434204, 1.0...   \n",
       "7609  [[-1.1461000442504883, -0.18153999745845795, 0...   \n",
       "7610  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7611  [[0.30003, 0.34859, -0.2896, -0.30224, -0.5052...   \n",
       "7612  [[-0.010166999883949757, 0.020193999633193016,...   \n",
       "\n",
       "                                   fullSizeVectorMatrix  \n",
       "0     [[-0.4204699993133545, 0.5652599930763245, -0....  \n",
       "1     [[-1.23580002784729, -0.5812699794769287, 0.20...  \n",
       "2     [[-0.1823199987411499, 0.9699699878692627, 0.3...  \n",
       "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4     [[-0.3551799952983856, 0.48030000925064087, 0....  \n",
       "...                                                 ...  \n",
       "7608  [[0.5829600095748901, 0.44516998529434204, 1.0...  \n",
       "7609  [[-1.1461000442504883, -0.18153999745845795, 0...  \n",
       "7610  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "7611  [[0.300029993057251, 0.3485899865627289, -0.28...  \n",
       "7612  [[-0.010166999883949757, 0.020193999633193016,...  \n",
       "\n",
       "[7613 rows x 8 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "n_filters = 10\n",
    "kernel_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_dev, y_train, y_dev = train_test_split(rawData, target, test_size=0.33)\n",
    "\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_dev = np.asarray(y_dev).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-296-1041f616f5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# as tf.dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectorList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdev_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectorList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    642\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \"\"\"\n\u001b[0;32m--> 644\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2782\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2784\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2785\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 113\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "# as tf.dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((df_train['vectorList'].values,y_train))\n",
    "dev_ds = tf.data.Dataset.from_tensor_slices((df_dev['vectorList'],y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedded_sequences = layers.Input(shape = (None,gloveSize) ,ragged=True)\n",
    "\n",
    "#swivel = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\", output_shape=[20], input_shape=[], \n",
    "#                           dtype=tf.string, trainable=True)\n",
    "\n",
    "conv1 = layers.Conv1D(n_filters, kernel_size)(embedded_sequences) #  activation='relu'?\n",
    "maxPool1  = layers.MaxPooling1D()(conv1)\n",
    "flatten = layers.Flatten()(maxPool1)\n",
    "preds = layers.Dense(2, activation='softmax')(flatten)\n",
    "# OR preds = layers.Dense(1, activation='sigmoid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(embedded_sequences, preds)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /home/rasoluci/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /home/rasoluci/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /home/rasoluci/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected input_5 to have 3 dimensions, but got array with shape (33, 25)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-a22ee57bb6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train_ds, validation_data=dev_ds,\n\u001b[0;32m----> 2\u001b[0;31m           epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    682\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1591\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3926\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /home/rasoluci/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /home/rasoluci/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    /home/rasoluci/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected input_5 to have 3 dimensions, but got array with shape (33, 25)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=dev_ds,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
